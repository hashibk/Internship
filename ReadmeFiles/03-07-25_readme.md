# ğŸ§  Mall Customer Segmentation and Classification using Clustering & ML

This notebook performs **unsupervised clustering** and **supervised classification** on mall customer data using various techniques including PCA, KMeans, Random Forest, and LightGBM.

---

## ğŸ“‚ Dataset Used

**Mall_Customers.csv**  
Contains customer information with the following columns:
- `CustomerID`
- `Genre`
- `Age`
- `Annual Income (k$)`
- `Spending Score (1-100)`

---

## ğŸ”§ Workflow Summary

### 1. ğŸ“Š Data Exploration & Cleaning
- Check for missing and duplicate values
- Drop `CustomerID` as it's irrelevant for modeling
- Encode the categorical column `Genre` using `LabelEncoder`

### 2. ğŸ§¹ Outlier Removal
- Use **IQR method** to calculate upper and lower bounds
- Remove data points outside these bounds

### 3. ğŸ“ Feature Scaling
- Apply `StandardScaler` to normalize numerical features

### 4. ğŸ”» Dimensionality Reduction (PCA)
- Reduce data to 2 principal components for better clustering and visualization

---

## ğŸ“ KMeans Clustering

### Steps:
- Elbow Method: Plot SSE vs. k to find optimal clusters
- Silhouette Score: Evaluate clustering quality
- Davies-Bouldin Index: Confirm cluster compactness and separation
- Visualize clusters in:
  - PCA-reduced space
  - Original feature space (`Annual Income` vs `Spending Score`)

### Output:
- Final clustering with `k=4`
- Clusters assigned to each data point
- New customers can be classified into a cluster using the trained pipeline

---

## ğŸ§  Random Forest Classification

### Goal:
Use the clustering labels as the target variable to train a classifier

### Steps:
- `train_test_split()` on data with cluster labels
- Apply `GridSearchCV` on `RandomForestClassifier` to tune:
  - `n_estimators`
  - `max_depth`
  - `min_samples_split`
  - `min_samples_leaf`
- Evaluate with:
  - Accuracy
  - Confusion Matrix
  - Classification Report

---

## âš¡ LightGBM Classification

### Goal:
Repeat classification with a high-performance gradient boosting model

### Steps:
- Set up `LGBMClassifier` for multiclass prediction
- Apply `GridSearchCV` with:
  - `n_estimators`, `max_depth`, `learning_rate`
  - `num_leaves`, `min_child_samples`, `subsample`, `colsample_bytree`
- Use `StratifiedKFold` cross-validation
- Evaluate using:
  - Accuracy
  - Classification Report

---

## ğŸ§ª Predicting a New Customer

A synthetic customer:
```python
[Genre=1, Age=30, Annual Income=70, Spending Score=60]
Was passed through the full pipeline (scaling â†’ PCA â†’ clustering) to predict the cluster they would belong to.

ğŸ“ˆ Evaluation Metrics Used

Silhouette Score â†’ Higher is better (closer to 1)
Davies-Bouldin Index â†’ Lower is better (closer to 0)
Accuracy, Classification Report, and Confusion Matrix for model evaluation
ğŸ“¦ Dependencies

pandas
numpy
matplotlib
seaborn
scikit-learn
lightgbm
You can install them via:

pip install pandas numpy matplotlib seaborn scikit-learn lightgbm
ğŸ§© File Structure

03-07-25_RandomForest-LightGBM_MallCustomers.ipynb   # Jupyter notebook with full code
Mall_Customers.csv                                   # Input dataset
readme.md                                            # This file